# =============================================================================
# ADVERSARIAL DEBIASING TRAINING CONFIGURATION
# =============================================================================
# This configuration file controls the training of medical image classification
# models with adversarial debiasing to remove age-related bias from learned features.
#
# Key Features:
# - Multi-label disease classification (14 conditions)
# - Adversarial age group prediction with Gradient Reversal Layer (GRL)
# - Scheduled lambda training (Ganin-style)
# - Support for both categorical and ordinal age prediction
# - Comprehensive monitoring and checkpointing
# =============================================================================

# =============================================================================
# OUTPUT AND LOGGING SETTINGS
# =============================================================================
# These control where training outputs, logs, and checkpoints are saved
out_name_prefix: 'mimic_mdn_experiment'  # Prefix for experiment names
out_base_dir: './outputs'                # Base directory for all outputs
log_dir: './logs'                        # TensorBoard logs directory
checkpoint_dir: './checkpoints'          # Model checkpoints directory

# =============================================================================
# DATA PATHS - UPDATE THESE WITH YOUR ACTUAL PATHS
# =============================================================================
# Main dataset splits (image paths and labels)
train_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/train_mimic.csv'
val_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/val_mimic.csv'
test_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/test_mimic.csv'

# Detailed metadata (includes age information for adversarial training)
train_details_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/train_final.csv'
val_details_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/val_final.csv'
test_details_csv: '/home/4tb/mimic/files/mimic-cxr-jpg/data_csv/csv/test_final.csv'

# Image data directory (where actual image files are stored)
img_data_dir: '/home/4tb/mimic/files/mimic-cxr-jpg/2.1.0/files/'

# =============================================================================
# MODEL ARCHITECTURE SETTINGS
# =============================================================================
# Choose the model architecture to use
model_type: 'DenseNetAgeAdv'  # Options: 'DenseNet', 'ResNet', 'VisionTransformer', 'DenseNetAgeAdv'
                               # DenseNetAgeAdv includes adversarial training capabilities

# Main task configuration
num_classes_main: 14  # Number of disease conditions to predict (multi-label)

# Image preprocessing
image_size: [224, 224]  # Input image dimensions (height, width)

# =============================================================================
# ADVERSARIAL TRAINING SETTINGS
# =============================================================================
# These parameters control the adversarial debiasing process

# Core adversarial settings
debias_enable: true                    # Master switch: true=enable debiasing, false=disable
adv_age_lambda: 0.5                    # Maximum lambda value for adversarial loss weight
use_scheduled_lambda: true             # Use Ganin-style lambda scheduling (recommended)

# Lambda scheduling parameters
lambda_warmup_frac: 0.3                # Warm-up fraction (first 30% of training steps)
                                       # Lambda starts at ~0 and ramps up to adv_age_lambda

# Age adversary architecture
age_mode: "categorical"                # Age prediction mode:
                                       # - "categorical": Standard 4-way classification
                                       # - "ordinal": Cumulative probability (P(age>X))
age_head_hidden: 256                   # Hidden layer size for age adversary (capacity)
age_head_dropout: 0.2                  # Dropout rate for age adversary (regularization)

# =============================================================================
# TRAINING HYPERPARAMETERS
# =============================================================================
# These control the training process and optimization

# Batch and data loading
batch_size_main: 64                    # Batch size (reduced from 150 for GPU memory)
num_workers: 4                         # Number of data loading workers (adjust for CPU cores)
epochs_main: 1                         # Test with 1 epoch

# =============================================================================
# CHECKPOINT AND SAVING SETTINGS
# =============================================================================
# These control model checkpointing and saving behavior

save_all_checkpoints: False            # Save all checkpoints (true) or only best (false)
checkpoint_save_top_k: 3               # Keep top K best checkpoints
checkpoint_save_every_n_steps: 100     # Save checkpoint every N steps (if save_all_checkpoints=true)
checkpoint_cleanup_keep_last: 3        # Keep last N checkpoints during cleanup

# =============================================================================
# EARLY STOPPING SETTINGS
# =============================================================================
# These control when to stop training early

enable_early_stopping: True            # Enable early stopping (true) or train full epochs (false)
early_stopping_patience: 10            # Stop if no improvement for N epochs

# =============================================================================
# AGE GROUPS CONFIGURATION
# =============================================================================
# Define age groups for adversarial training
# Format: [(min_age, max_age, group_name), ...]
# Note: -1 represents infinity (no upper bound)
age_groups:
  - [0, 36, "0-36"]    # Young adults
  - [36, 50, "36-50"]  # Middle-aged adults
  - [50, 65, "50-65"]  # Older adults
  - [65, -1, "65+"]    # Elderly (-1 = no upper limit)

# =============================================================================
# CONFIGURATION EXAMPLES AND RECOMMENDATIONS
# =============================================================================

# Conservative settings (start here for stability):
# adv_age_lambda: 0.3
# age_head_hidden: 128
# age_head_dropout: 0.3
# lambda_warmup_frac: 0.4

# Aggressive settings (for stronger debiasing):
# adv_age_lambda: 0.8
# age_head_hidden: 512
# age_head_dropout: 0.1
# lambda_warmup_frac: 0.2

# Baseline (no debiasing):
# debias_enable: false

# Ordinal mode (alternative to categorical):
# age_mode: "ordinal"

# =============================================================================
# MONITORING AND EVALUATION
# =============================================================================
# The training will automatically log:
# - Main task metrics: per-label AUROC, macro/micro AUROC
# - Adversarial metrics: age prediction loss, current lambda value
# - Training metrics: total loss, learning rate, gradient norms
# - Images: sample training images for visualization

# Use TensorBoard to monitor training:
# tensorboard --logdir ./logs

# After training, run linear probe to evaluate age bias removal:
# python linear_probe_age.py --config linear_probe_config.yaml
